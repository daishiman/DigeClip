```markdown
# テスト戦略

> **前提**:
> - **コストをかけずに、初心者でもテストできる**体制を優先
> - システム規模が大きくなった際にも**段階的に拡張**しやすい設計
> - まずは**最重要機能**をテスト、余裕があれば非機能・E2Eまで拡張

---

## 1. テストレベル

1. **単体テスト (Unit Test)**
   - **対象**: 関数や小規模コンポーネント（Next.js のAPI Route単体、認証ロジック、要約生成ロジックなど）
   - **目的**: 各モジュールが**単体で**正しく動作するかを確認
   - **実施タイミング**: 開発者が機能追加/修正する度にローカル実施 + CI上で自動実行

2. **結合テスト (Integration Test)**
   - **対象**: APIとDB連携/外部サービス連携（Supabase, Discord Webhook, AIモデルAPI）など
   - **目的**: **モジュール間**の連携が正常に動作するかを確認
   - **実施タイミング**: 大きな機能ブランチ完了、Pull Request時など

3. **システムテスト (E2E)**
   - **対象**: ユーザー操作の流れ（ログイン → 新着検出 → AI要約 → Discord通知 → アプリ画面で閲覧 など）
   - **目的**: システム全体を通して**一連の操作**が意図通りに動作するか確認
   - **実施タイミング**: リリース前のステージング環境で定期 or 主要機能追加時

4. **UAT (ユーザー受け入れテスト)**
   - **対象**: 管理者/一般ユーザーが実際に触り、本番運用イメージで最終確認
   - **目的**: 要件・UI/UXがユーザー要望とズレていないか評価
   - **実施タイミング**: 大きめのリリース前、あるいはフェーズ完了前

---

## 2. テスト項目

1. **機能テスト (正常系/異常系)**
   - **正常系**:
     - 新規ユーザー登録、ログイン/ログアウト
     - 要約機能（AIモデル呼び出し、結果保存）
     - RSS/YouTube監視ジョブ → DB保存
     - Discord通知（サムネ付きEmbed）
     - タグ登録/削除、検索フィルタ など
   - **異常系**:
     - ログイン失敗（不正パスワード、アカウントロックなど）
     - AIモデル呼び出し失敗（API Key不備、タイムアウト）
     - DB保存時のエラー（容量超過、接続切断など）
     - Discord Webhookエラー（URL不正、403 Forbiddenなど）

2. **非機能テスト**
   - **性能テスト**:
     - ページネーションで大量コンテンツがある際、応答速度が許容範囲内か
     - Cronジョブで同時多数のRSSを処理して問題ないか
   - **セキュリティテスト**:
     - 認証/認可の欠陥、CSRFトークン有効性
     - .env / 機密情報の漏えいがないか
   - **操作性テスト**: (簡易)
     - ダッシュボードや管理画面がUI的に使いやすいか

---

## 3. テスト環境

1. **ステージング**:
   - Vercel の Preview Deploy 機能 → PRごとに自動生成される環境
   - Supabase: テスト用テーブル or テスト用プロジェクトを別途用意
   - テスト用のDiscord Webhook (開発専用チャンネル)

2. **本番相当の構成**:
   - 主要機能確認や負荷テストを実施するなら、本番同等にDB/設定を用意
   - Supabase の無料枠内でもENVを分ける (プロジェクト2つにしてデータ分離)

3. **テストデータの扱い**:
   - テスト用アカウント: `test-user@example.com` / `test-pass123` など
   - 大量の記事/動画IDを用意 → テスト的にRSSに混ぜ込む
   - テスト終了後はリセット/クリーンアップ

---

## 4. 自動テストカバレッジ目標

1. **単体テスト**:
   - 主要ロジック（AI要約、Discord送信、RSS解析等）は**最低限** 70% 以上
   - 全機能100% は目指さず、**重要処理**を優先カバー

2. **結合テスト**:
   - 認証 + DB連携 + AI呼び出しなど主要経路を1,2ケースずつ
   - 毎回フルテストでなく**主要機能が壊れていないか**を確認

3. **E2Eテスト**:
   - ログイン→YouTube監視→DB保存→要約→Discord通知→アプリ画面表示
   - クリティカルパスを1,2のシナリオで自動化
   - UI変更多い時は保守コストに注意

---

## 5. テスト管理ツール

1. **軽量管理**:
   - **GitHub Projects** / Issue でテストケース追跡
   - スプレッドシート: 「テスト項目表」作成 (ID, 手順, 期待結果, 実施可否など)

2. **本格導入** (将来):
   - TestRail, Xray for Jira 等 → 大規模開発向け
   - 初期導入コストあるため**小規模MVPでは不要**

---

## 6. リリース判定基準

1. **バグ残数**:
   - 重大バグ (サービス停止/データ破壊レベル) は 0
   - 中程度バグは**次リリース対応**でもOKか判断 → Issue化

2. **パフォーマンス指標**:
   - 1ユーザー操作あたり**応答1秒以内**程度を目標 (ページネーション時)
   - Cronジョブが**許容時間**(例: 1分以内)でRSS全取得 → 超過ならスケールか対策

3. **テスト完了率**:
   - 重要シナリオ (AI要約/認証/通知) は 100% 実施
   - 余力があれば他機能も網羅 → 未実施項目はリリースメモに記載

4. **承認フロー**:
   - 開発メンバー/PMがテスト結果確認 → OK で本番デプロイ
   - 重大バグがあれば修正後に再テスト

---

### まとめ

- **テストレベル**: 単体 → 結合 → E2E → UAT の段階的実施
- **テスト項目**: まずは**主要機能 (認証, 要約, 通知)** を中心に正常・異常系
- **環境**: Vercel Preview + Supabaseテスト用プロジェクト
- **カバレッジ目標**: 重要ロジック優先で70%程度
- **ツール**: 小規模はGitHub Issue/Projects + スプレッドシートで十分
- **リリース判定**: 重大バグ0 & パフォーマンス目標達成 → OK

これにより、初心者でも少ないコストでテストを回しつつ、将来的な機能拡張時にも対応しやすい構成を実現する。
```